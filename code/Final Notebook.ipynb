{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ant Miner\n",
    "### A swarm based Data Classification Algorithm\n",
    "##### Jonathan Zerez and Nathan Lepore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we set out to recreate and expand upon Ant Miner, the Ant Colony Algorithm (ACA) for data classification originally proposed by Parpinelli et al. Specifically, they propose a method of using an ACA in order to discover rules that best discriminate between different classes present in a dataset based on measurable attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class and Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catagorization:\n",
    "    def __init__(self, num_ants, num_rules_converge, data, attributes, classes):\n",
    "        self.num_ants = num_ants\n",
    "        self.num_rules_converge = num_rules_converge\n",
    "        self.data = data\n",
    "        self.original_data = data.copy()\n",
    "        self.attributes = attributes\n",
    "\n",
    "        self.classes = classes\n",
    "        self.heuristic = self.calc_heuristic()\n",
    "        self.pharamones = self.init_pharamones()\n",
    "        self.discovered_rules = []\n",
    "        self.qualities = [[]]\n",
    "        self.leftover_cases = 35\n",
    "        self.init_ants() \n",
    "        \n",
    "    def init_ants(self):\n",
    "        min_cases = 5\n",
    "        self.ants = [Ant(self.pharamones, self.heuristic, self.attributes, min_cases, self.classes) for i in range(self.num_ants)]\n",
    "        \n",
    "    def run_simulation(self, verbose = False, supress_output = False):\n",
    "        while len(self.data) > self.leftover_cases:\n",
    "            self.converged_rules = 1\n",
    "            best_rule = []\n",
    "            best_quality = -1\n",
    "            consequent = None\n",
    "            \n",
    "            for j, ant in enumerate(self.ants):\n",
    "                self.run_one_ant(ant)\n",
    "                \n",
    "                    \n",
    "                if best_quality < 0 and set(self.ants[j-1].rule) == set(ant.rule) and ant.rule:\n",
    "                    self.converged_rules += 1\n",
    "                else:\n",
    "                    self.converged_rules = 1\n",
    "                if self.converged_rules == self.num_rules_converge:\n",
    "                    print('rules have converged')\n",
    "                    break\n",
    "                if ant.quality > best_quality:\n",
    "                    best_quality = ant.quality\n",
    "                    best_rule = ant.rule\n",
    "                    consequent = ant.consequent\n",
    "            n = self.remove_relevant_cases(best_rule, consequent)\n",
    "            assert(not self.find_relevant_cases(best_rule))\n",
    "            self.discovered_rules.append((best_rule, consequent, best_quality, n))\n",
    "            self.pharamones = self.init_pharamones()\n",
    "            self.init_ants()\n",
    "            self.qualities.append([])\n",
    "            if verbose: print('remaining data: ', len(self.data))\n",
    "        if not supress_output: print('simulation done. Remaining cases: ', len(self.data))\n",
    "            \n",
    "    def run_one_ant(self, ant):\n",
    "        ant.pharamones = self.pharamones\n",
    "        ant.add_terms(self.data)\n",
    "        q = self.prune_ant(ant)\n",
    "        consequent = self.calc_consequent(ant.rule)\n",
    "        self.update_pharamones(ant.rule, q)\n",
    "        ant.quality = q\n",
    "        ant.consequent = consequent\n",
    "        self.qualities[-1].append(q)\n",
    "        \n",
    "    def calc_heuristic(self):\n",
    "        probs = {}\n",
    "        heuristic = {}\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                for k in self.classes:\n",
    "                    a = [game for game in self.data if k == game[-1]]\n",
    "                    b = [game for game in a if j == game[index]]\n",
    "                    p = len(b)/len(self.data)\n",
    "                    c = probs.get((index,j),[])\n",
    "                    c.append(np.log2(p**p))\n",
    "                    probs[(index,j)] = c\n",
    "                heuristic[(index,j)] = -sum(probs[(index,j)])\n",
    "        return heuristic\n",
    "\n",
    "    def pick_best_rule(self):\n",
    "        most_correct = 0\n",
    "        best_ant = None\n",
    "        for ant in self.ants:\n",
    "            consequence, num_correct = self.calc_num_correct(ant.rule)\n",
    "            ant.consequence = consequence\n",
    "            if num_correct > most_correct:\n",
    "                most_correct = num_correct\n",
    "                best_ant = ant\n",
    "        return most_correct, best_ant\n",
    "    \n",
    "    def find_relevant_cases(self, rule):\n",
    "        relevant_cases = self.data.copy()\n",
    "        for case in self.data:\n",
    "            for term in rule:\n",
    "                if case[term[0]] != term[1]:\n",
    "                    relevant_cases.remove(case)\n",
    "                    break\n",
    "        return relevant_cases\n",
    "    \n",
    "    def remove_relevant_cases(self, rule, consequent):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        count = 0\n",
    "        for case in relevant_cases:\n",
    "            self.data.remove(case)\n",
    "            if case[-1] == consequent:\n",
    "                count += 1\n",
    "        return count\n",
    "    def calc_consequent(self, rule):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        classes = {}\n",
    "        if not relevant_cases:\n",
    "            relevant_cases = self.data\n",
    "            \n",
    "        for case in relevant_cases:\n",
    "            classes[str(case[-1])] = classes.get(str(case[-1]), 0) + 1\n",
    "        res = max(classes, key=classes.get)\n",
    "        return res\n",
    "    \n",
    "    def prune_ant(self, ant):\n",
    "        \"\"\"Iteratively goes through the rulelist for an ant and sees which rules are not helping the quality of the rule\"\"\"\n",
    "        n = len(ant.rule)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        for iteration in range(n):\n",
    "            max_delta_quality = 0\n",
    "            best_new_rule = ant.rule\n",
    "            consequent = self.calc_consequent(ant.rule)\n",
    "            base_quality = self.calc_quality(ant.rule, consequent)\n",
    "            \n",
    "            for i, term in enumerate(ant.rule):\n",
    "                new_rule = ant.rule[0:i] + ant.rule[i+1:]\n",
    "                new_consequent = self.calc_consequent(new_rule)\n",
    "                new_quality = self.calc_quality(new_rule, new_consequent)\n",
    "                if max_delta_quality <= new_quality - base_quality:\n",
    "                    max_delta_quality = new_quality - base_quality\n",
    "                    best_new_rule = new_rule\n",
    "            if max_delta_quality >= 0:\n",
    "                if best_new_rule:\n",
    "                    ant.rule = best_new_rule\n",
    "                    max_delta_quality = 0\n",
    "            else:\n",
    "                break\n",
    "        return max_delta_quality + base_quality\n",
    "        \n",
    "    def calc_quality(self, rule, consequent):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        num_cases_covered = len(relevant_cases)\n",
    "        num_cases_not_covered = len(self.data) - len(relevant_cases)\n",
    "        \n",
    "        true_positives = len([case for case in relevant_cases if case[-1] == consequent])\n",
    "        false_positives = len(relevant_cases) - true_positives\n",
    "        false_negatives = len([case for case in self.data if case not in relevant_cases and case[-1] == consequent])\n",
    "        true_negatives = len(self.data) - len(relevant_cases) - false_negatives\n",
    "        \n",
    "        sensitivity = true_positives / (true_positives + false_negatives)\n",
    "        if true_negatives == 0: return 0\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "        \n",
    "        return sensitivity * specificity\n",
    "        \n",
    "    def init_pharamones(self):\n",
    "        pharamones = {}\n",
    "        total = 0\n",
    "        for attribute in self.attributes.keys():\n",
    "            total += len(self.attributes[attribute])\n",
    "            \n",
    "        initial_value = 1/total\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                pharamones[(index,j)] = initial_value\n",
    "        return pharamones\n",
    "    \n",
    "    def update_pharamones(self, rule, quality):\n",
    "        for term in rule:\n",
    "            self.pharamones[(term[0], term[1])] += quality\n",
    "        normalization_factor = sum(self.pharamones.values())\n",
    "        keys = self.pharamones.keys()\n",
    "        for key in keys:\n",
    "            self.pharamones[key] /= normalization_factor\n",
    "        \n",
    "        assert(sum(self.pharamones.values()) - 1 < 0.0001)\n",
    "        \n",
    "    def evaluate_discovered_rules(self, data):\n",
    "        num_correct = 0\n",
    "        num_total = len(data)\n",
    "        self.data = data\n",
    "        for rule in self.discovered_rules:\n",
    "            num_correct += self.remove_relevant_cases(rule[0], rule[1])\n",
    "        return num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ant:\n",
    "    def __init__(self,pharamones, heuristic, attributes, min_cases_per_rule, classes):\n",
    "        \"\"\n",
    "        self.rule = []\n",
    "        self.pharamones = pharamones\n",
    "        self.heuristic = heuristic\n",
    "        self.decision = np.zeros((9,3))\n",
    "        self.k = 2\n",
    "        self.classes = classes\n",
    "        self.attributes = attributes\n",
    "        self.min_cases_per_rule = min_cases_per_rule\n",
    "        self.used_attributes = []\n",
    "        \n",
    "    def add_terms(self, data):\n",
    "        \"adds a term to the ruleset based on the pharamone trail and heuristic function\"\n",
    "        quit = False\n",
    "        tries = 0\n",
    "        for i in self.attributes.keys():\n",
    "            probs = self.calc_prob()\n",
    "            picking = True\n",
    "            while picking:\n",
    "                term = self.pick_term(probs)\n",
    "                if len(self.find_relevant_cases(self.rule+[term], data)) > self.min_cases_per_rule:\n",
    "                    if term[0] not in self.used_attributes:\n",
    "                        self.used_attributes.append(term[0])\n",
    "                        picking = False\n",
    "                else:\n",
    "                    tries += 1\n",
    "                if tries > 10 and self.rule:\n",
    "                    picking = False\n",
    "                    quit = True\n",
    "                if tries > 25:\n",
    "                    quit = True\n",
    "            if not quit:\n",
    "                self.rule.append(term)\n",
    "            else:\n",
    "                break\n",
    "    def normalize(self, function):\n",
    "        norm = {}\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                num = function(index, j)\n",
    "                if num == 0:\n",
    "                    norm[(index,j)] = 0\n",
    "                    continue\n",
    "                unused_attributes = len(self.attributes.keys())-len(self.rule)\n",
    "                normalization_factor = 0\n",
    "                for jj in self.attributes[i]:\n",
    "                    normalization_factor += function(index, jj)\n",
    "                norm[(index,j)] = num / (unused_attributes * normalization_factor)\n",
    "        return norm\n",
    "        \n",
    "    def normalize_heuristic(self):\n",
    "        def f(i, j):\n",
    "            return np.log2(self.k) - self.heuristic[(i,j)]\n",
    "        return self.normalize(f)\n",
    "    \n",
    "    def calc_prob(self):\n",
    "        self.normalized_heuristic = self.normalize_heuristic()\n",
    "        def f(i, j):\n",
    "            if i not in self.used_attributes:\n",
    "                return self.pharamones[(i,j)] * self.normalized_heuristic[(i,j)]\n",
    "            else:\n",
    "                return 0\n",
    "        return self.normalize(f)\n",
    "    \n",
    "    def pick_term(self, probs):\n",
    "        index = np.random.choice(len(probs), 1, p = list(probs.values()))\n",
    "        index = index[0]\n",
    "        term = list(probs.keys())[index]\n",
    "        return term\n",
    "    \n",
    "    def find_relevant_cases(self, rule, data):\n",
    "        relevant_cases = data.copy()\n",
    "        for case in data:\n",
    "            for term in rule:\n",
    "                if case[term[0]] != term[1]:\n",
    "                    relevant_cases.remove(case)\n",
    "                    break\n",
    "        return relevant_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "def get_train_and_test_from_file(file, special = None):\n",
    "    data = open(file, 'r')\n",
    "    data_listed = []\n",
    "\n",
    "    for i in data.readlines():\n",
    "        if not special:\n",
    "            data_listed.append(tuple(str.split(i[:-1], ',')))\n",
    "        elif special == 'breast':\n",
    "            line = str.split(i[:-1], ',')\n",
    "            c = line.pop(0)\n",
    "            line.append(c)\n",
    "            data_listed.append(tuple(line))\n",
    "        elif special == 'wisconsin':\n",
    "            data_listed.append(tuple(str.split(i[:-1], ',')[1:]))\n",
    "    n=len(data_listed)\n",
    "    train_ind = np.random.choice(n, round(n*0.8), replace=False)\n",
    "    train = [data_listed[index] for index in train_ind]\n",
    "    test = [case for case in data_listed if case not in train]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Breast Cancer Data (Wisconsin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  27\n",
      "Average Accuracy is:  0.8192771084337349\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  9.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/breast-cancer-wisconsin.data', 'wisconsin')\n",
    "    attribute_list = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n",
    "    attributes = {}\n",
    "    for attribute in attribute_list:\n",
    "        attributes[attribute] = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "    classes = ['2', '4']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Tic-Tac-Toe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  30\n",
      "Average Accuracy is:  0.6875\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  4.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/tic-tac-toe.data')\n",
    "    attributes = {}\n",
    "    for i in range(9):\n",
    "        attributes[i] = ['x','o','b']\n",
    "\n",
    "    classes = ['positive', 'negative']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "    \n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Breast Cancer Data (Ljubljana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  22\n",
      "Average Accuracy is:  0.6181818181818182\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  3.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/breast-cancer.data', 'breast')\n",
    "\n",
    "\n",
    "    attributes = {}\n",
    "    attribute_list = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']\n",
    "\n",
    "    attributes['age'] = ('10-19',' 20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99')\n",
    "    attributes['menopause'] = ('lt40', 'ge40', 'premeno')\n",
    "    attributes['tumor-size'] = ('0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44','45-49', '50-54', '55-59')\n",
    "    attributes['inv-nodes'] = ('0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-20', '21-23', '24-26', '27-29', '30-32', '33-35', '36-39')\n",
    "    attributes['node-caps'] = ('yes', 'no')\n",
    "    attributes['deg-malig'] = (1,2,3)\n",
    "    attributes['breast'] = ('left', 'right')\n",
    "    attributes['breast-quad'] = ('left-up', 'left-low', 'right-up', 'right-low', 'central')\n",
    "    attributes['irradiat'] = ('yes', 'no')\n",
    "\n",
    "    classes = ['no-recurrence-events', 'recurrence-events']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "    \n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweeping number of Ants\n",
    "#### Warning! These cells take a really long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 15\n",
    "# Number of ants to use\n",
    "num_ants_vec = [5, 10, 15, 20, 25]\n",
    "\n",
    "all_accuracies = []\n",
    "all_num_rules = []\n",
    "all_num_terms = []\n",
    "for num_ants in num_ants_vec:\n",
    "    all_accuracies.append([])\n",
    "    all_num_rules.append([])\n",
    "    all_num_terms.append([])\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        train, test = get_train_and_test_from_file('../data/breast-cancer-wisconsin.data', 'wisconsin')\n",
    "        attribute_list = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n",
    "        attributes = {}\n",
    "        for attribute in attribute_list:\n",
    "            attributes[attribute] = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "        classes = ['2', '4']\n",
    "\n",
    "        s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "        s.run_simulation(supress_output = True)\n",
    "        all_accuracies[-1].append(s.evaluate_discovered_rules(test))\n",
    "        all_num_rules[-1].append(len(s.discovered_rules))\n",
    "        all_num_terms[-1].append(np.mean([len(rule[1]) for rule in s.discovered_rules]))\n",
    "        \n",
    "plt.boxplot(all_accuracies, positions=[n/5 for n in num_ants_vec])\n",
    "plt.title('Accuracy vs Number of Ants Used (Wisconsin Breast Cancer)')\n",
    "plt.xlabel('Number of Ants Used (x5)')\n",
    "plt.ylabel('Accuracy of Ruleset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
