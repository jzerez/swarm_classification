{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ant Miner\n",
    "### A swarm based Data Classification Algorithm\n",
    "##### Jonathan Zerez and Nathan Lepore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we set out to recreate and expand upon Ant Miner, the Ant Colony Algorithm (ACA) for data classification originally proposed by Parpinelli et al. Specifically, they propose a method of using an ACA in order to discover rules that best discriminate between different classes present in a dataset based on measurable attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class and Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catagorization:\n",
    "    def __init__(self, num_ants, num_rules_converge, data, attributes, classes):\n",
    "        self.num_ants = num_ants\n",
    "        self.num_rules_converge = num_rules_converge\n",
    "        self.data = data\n",
    "        self.original_data = data.copy()\n",
    "        self.attributes = attributes\n",
    "\n",
    "        self.classes = classes\n",
    "        self.heuristic = self.calc_heuristic()\n",
    "        self.pharamones = self.init_pharamones()\n",
    "        self.discovered_rules = []\n",
    "        self.qualities = [[]]\n",
    "        self.leftover_cases = 35\n",
    "        self.init_ants() \n",
    "        \n",
    "    def init_ants(self):\n",
    "        min_cases = 5\n",
    "        self.ants = [Ant(self.pharamones, self.heuristic, self.attributes, min_cases, self.classes) for i in range(self.num_ants)]\n",
    "        \n",
    "    def run_simulation(self, verbose = False, supress_output = False):\n",
    "        while len(self.data) > self.leftover_cases:\n",
    "            self.converged_rules = 1\n",
    "            best_rule = []\n",
    "            best_quality = -1\n",
    "            consequent = None\n",
    "            \n",
    "            for j, ant in enumerate(self.ants):\n",
    "                self.run_one_ant(ant)\n",
    "                \n",
    "                    \n",
    "                if best_quality < 0 and set(self.ants[j-1].rule) == set(ant.rule) and ant.rule:\n",
    "                    self.converged_rules += 1\n",
    "                else:\n",
    "                    self.converged_rules = 1\n",
    "                if self.converged_rules == self.num_rules_converge:\n",
    "                    print('rules have converged')\n",
    "                    break\n",
    "                if ant.quality > best_quality:\n",
    "                    best_quality = ant.quality\n",
    "                    best_rule = ant.rule\n",
    "                    consequent = ant.consequent\n",
    "            n = self.remove_relevant_cases(best_rule, consequent)\n",
    "            assert(not self.find_relevant_cases(best_rule))\n",
    "            self.discovered_rules.append((best_rule, consequent, best_quality, n))\n",
    "            self.pharamones = self.init_pharamones()\n",
    "            self.init_ants()\n",
    "            self.qualities.append([])\n",
    "            if verbose: print('remaining data: ', len(self.data))\n",
    "        if not supress_output: print('simulation done. Remaining cases: ', len(self.data))\n",
    "            \n",
    "    def run_one_ant(self, ant):\n",
    "        ant.pharamones = self.pharamones\n",
    "        ant.add_terms(self.data)\n",
    "        q = self.prune_ant(ant)\n",
    "        consequent = self.calc_consequent(ant.rule)\n",
    "        self.update_pharamones(ant.rule, q)\n",
    "        ant.quality = q\n",
    "        ant.consequent = consequent\n",
    "        self.qualities[-1].append(q)\n",
    "        \n",
    "    def calc_heuristic(self):\n",
    "        probs = {}\n",
    "        heuristic = {}\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                for k in self.classes:\n",
    "                    a = [game for game in self.data if k == game[-1]]\n",
    "                    b = [game for game in a if j == game[index]]\n",
    "                    p = len(b)/len(self.data)\n",
    "                    c = probs.get((index,j),[])\n",
    "                    c.append(np.log2(p**p))\n",
    "                    probs[(index,j)] = c\n",
    "                heuristic[(index,j)] = -sum(probs[(index,j)])\n",
    "        return heuristic\n",
    "\n",
    "    def pick_best_rule(self):\n",
    "        most_correct = 0\n",
    "        best_ant = None\n",
    "        for ant in self.ants:\n",
    "            consequence, num_correct = self.calc_num_correct(ant.rule)\n",
    "            ant.consequence = consequence\n",
    "            if num_correct > most_correct:\n",
    "                most_correct = num_correct\n",
    "                best_ant = ant\n",
    "        return most_correct, best_ant\n",
    "    \n",
    "    def find_relevant_cases(self, rule):\n",
    "        relevant_cases = self.data.copy()\n",
    "        for case in self.data:\n",
    "            for term in rule:\n",
    "                if case[term[0]] != term[1]:\n",
    "                    relevant_cases.remove(case)\n",
    "                    break\n",
    "        return relevant_cases\n",
    "    \n",
    "    def remove_relevant_cases(self, rule, consequent):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        count = 0\n",
    "        for case in relevant_cases:\n",
    "            self.data.remove(case)\n",
    "            if case[-1] == consequent:\n",
    "                count += 1\n",
    "        return count\n",
    "    def calc_consequent(self, rule):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        classes = {}\n",
    "        if not relevant_cases:\n",
    "            relevant_cases = self.data\n",
    "            \n",
    "        for case in relevant_cases:\n",
    "            classes[str(case[-1])] = classes.get(str(case[-1]), 0) + 1\n",
    "        res = max(classes, key=classes.get)\n",
    "        return res\n",
    "    \n",
    "    def prune_ant(self, ant):\n",
    "        \"\"\"Iteratively goes through the rulelist for an ant and sees which rules are not helping the quality of the rule\"\"\"\n",
    "        n = len(ant.rule)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        for iteration in range(n):\n",
    "            max_delta_quality = 0\n",
    "            best_new_rule = ant.rule\n",
    "            consequent = self.calc_consequent(ant.rule)\n",
    "            base_quality = self.calc_quality(ant.rule, consequent)\n",
    "            \n",
    "            for i, term in enumerate(ant.rule):\n",
    "                new_rule = ant.rule[0:i] + ant.rule[i+1:]\n",
    "                new_consequent = self.calc_consequent(new_rule)\n",
    "                new_quality = self.calc_quality(new_rule, new_consequent)\n",
    "                if max_delta_quality <= new_quality - base_quality:\n",
    "                    max_delta_quality = new_quality - base_quality\n",
    "                    best_new_rule = new_rule\n",
    "            if max_delta_quality >= 0:\n",
    "                if best_new_rule:\n",
    "                    ant.rule = best_new_rule\n",
    "                    max_delta_quality = 0\n",
    "            else:\n",
    "                break\n",
    "        return max_delta_quality + base_quality\n",
    "        \n",
    "    def calc_quality(self, rule, consequent):\n",
    "        relevant_cases = self.find_relevant_cases(rule)\n",
    "        num_cases_covered = len(relevant_cases)\n",
    "        num_cases_not_covered = len(self.data) - len(relevant_cases)\n",
    "        \n",
    "        true_positives = len([case for case in relevant_cases if case[-1] == consequent])\n",
    "        false_positives = len(relevant_cases) - true_positives\n",
    "        false_negatives = len([case for case in self.data if case not in relevant_cases and case[-1] == consequent])\n",
    "        true_negatives = len(self.data) - len(relevant_cases) - false_negatives\n",
    "        \n",
    "        sensitivity = true_positives / (true_positives + false_negatives)\n",
    "        if true_negatives == 0: return 0\n",
    "        specificity = true_negatives / (true_negatives + false_positives)\n",
    "        \n",
    "        return sensitivity * specificity\n",
    "        \n",
    "    def init_pharamones(self):\n",
    "        pharamones = {}\n",
    "        total = 0\n",
    "        for attribute in self.attributes.keys():\n",
    "            total += len(self.attributes[attribute])\n",
    "            \n",
    "        initial_value = 1/total\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                pharamones[(index,j)] = initial_value\n",
    "        return pharamones\n",
    "    \n",
    "    def update_pharamones(self, rule, quality):\n",
    "        for term in rule:\n",
    "            self.pharamones[(term[0], term[1])] += quality\n",
    "        normalization_factor = sum(self.pharamones.values())\n",
    "        keys = self.pharamones.keys()\n",
    "        for key in keys:\n",
    "            self.pharamones[key] /= normalization_factor\n",
    "        \n",
    "        assert(sum(self.pharamones.values()) - 1 < 0.0001)\n",
    "        \n",
    "    def evaluate_discovered_rules(self, data):\n",
    "        num_correct = 0\n",
    "        num_total = len(data)\n",
    "        self.data = data\n",
    "        for rule in self.discovered_rules:\n",
    "            num_correct += self.remove_relevant_cases(rule[0], rule[1])\n",
    "        return num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ant:\n",
    "    def __init__(self,pharamones, heuristic, attributes, min_cases_per_rule, classes):\n",
    "        \"\"\n",
    "        self.rule = []\n",
    "        self.pharamones = pharamones\n",
    "        self.heuristic = heuristic\n",
    "        self.decision = np.zeros((9,3))\n",
    "        self.k = 2\n",
    "        self.classes = classes\n",
    "        self.attributes = attributes\n",
    "        self.min_cases_per_rule = min_cases_per_rule\n",
    "        self.used_attributes = []\n",
    "        \n",
    "    def add_terms(self, data):\n",
    "        \"adds a term to the ruleset based on the pharamone trail and heuristic function\"\n",
    "        quit = False\n",
    "        tries = 0\n",
    "        for i in self.attributes.keys():\n",
    "            probs = self.calc_prob()\n",
    "            picking = True\n",
    "            while picking:\n",
    "                term = self.pick_term(probs)\n",
    "                if len(self.find_relevant_cases(self.rule+[term], data)) > self.min_cases_per_rule:\n",
    "                    if term[0] not in self.used_attributes:\n",
    "                        self.used_attributes.append(term[0])\n",
    "                        picking = False\n",
    "                else:\n",
    "                    tries += 1\n",
    "                if tries > 10 and self.rule:\n",
    "                    picking = False\n",
    "                    quit = True\n",
    "                if tries > 25:\n",
    "                    quit = True\n",
    "            if not quit:\n",
    "                self.rule.append(term)\n",
    "            else:\n",
    "                break\n",
    "    def normalize(self, function):\n",
    "        norm = {}\n",
    "        for index, i in enumerate(self.attributes.keys()):\n",
    "            for j in self.attributes[i]:\n",
    "                num = function(index, j)\n",
    "                if num == 0:\n",
    "                    norm[(index,j)] = 0\n",
    "                    continue\n",
    "                unused_attributes = len(self.attributes.keys())-len(self.rule)\n",
    "                normalization_factor = 0\n",
    "                for jj in self.attributes[i]:\n",
    "                    normalization_factor += function(index, jj)\n",
    "                norm[(index,j)] = num / (unused_attributes * normalization_factor)\n",
    "        return norm\n",
    "        \n",
    "    def normalize_heuristic(self):\n",
    "        def f(i, j):\n",
    "            return np.log2(self.k) - self.heuristic[(i,j)]\n",
    "        return self.normalize(f)\n",
    "    \n",
    "    def calc_prob(self):\n",
    "        self.normalized_heuristic = self.normalize_heuristic()\n",
    "        def f(i, j):\n",
    "            if i not in self.used_attributes:\n",
    "                return self.pharamones[(i,j)] * self.normalized_heuristic[(i,j)]\n",
    "            else:\n",
    "                return 0\n",
    "        return self.normalize(f)\n",
    "    \n",
    "    def pick_term(self, probs):\n",
    "        index = np.random.choice(len(probs), 1, p = list(probs.values()))\n",
    "        index = index[0]\n",
    "        term = list(probs.keys())[index]\n",
    "        return term\n",
    "    \n",
    "    def find_relevant_cases(self, rule, data):\n",
    "        relevant_cases = data.copy()\n",
    "        for case in data:\n",
    "            for term in rule:\n",
    "                if case[term[0]] != term[1]:\n",
    "                    relevant_cases.remove(case)\n",
    "                    break\n",
    "        return relevant_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "def get_train_and_test_from_file(file, special = None):\n",
    "    data = open(file, 'r')\n",
    "    data_listed = []\n",
    "\n",
    "    for i in data.readlines():\n",
    "        if not special:\n",
    "            data_listed.append(tuple(str.split(i[:-1], ',')))\n",
    "        elif special == 'breast':\n",
    "            line = str.split(i[:-1], ',')\n",
    "            c = line.pop(0)\n",
    "            line.append(c)\n",
    "            data_listed.append(tuple(line))\n",
    "        elif special == 'wisconsin':\n",
    "            data_listed.append(tuple(str.split(i[:-1], ',')[1:]))\n",
    "    n=len(data_listed)\n",
    "    train_ind = np.random.choice(n, round(n*0.8), replace=False)\n",
    "    train = [data_listed[index] for index in train_ind]\n",
    "    test = [case for case in data_listed if case not in train]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Breast Cancer Data (Wisconsin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  27\n",
      "Average Accuracy is:  0.8192771084337349\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  9.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/breast-cancer-wisconsin.data', 'wisconsin')\n",
    "    attribute_list = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n",
    "    attributes = {}\n",
    "    for attribute in attribute_list:\n",
    "        attributes[attribute] = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "    classes = ['2', '4']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Tic-Tac-Toe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  30\n",
      "Average Accuracy is:  0.6875\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  4.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/tic-tac-toe.data')\n",
    "    attributes = {}\n",
    "    for i in range(9):\n",
    "        attributes[i] = ['x','o','b']\n",
    "\n",
    "    classes = ['positive', 'negative']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "    \n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Miner on Breast Cancer Data (Ljubljana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation done. Remaining cases:  22\n",
      "Average Accuracy is:  0.6181818181818182\n",
      "Accuracy std. is:  0.0\n",
      "Average number of rules per ruleset is:  3.0\n",
      "Number of rules per ruleset std. is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 1\n",
    "# Number of ants to use\n",
    "num_ants = 50\n",
    "\n",
    "accuracies = []\n",
    "num_rules = []\n",
    "for i in range(num_runs):\n",
    "    \n",
    "    train, test = get_train_and_test_from_file('../data/breast-cancer.data', 'breast')\n",
    "\n",
    "\n",
    "    attributes = {}\n",
    "    attribute_list = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']\n",
    "\n",
    "    attributes['age'] = ('10-19',' 20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99')\n",
    "    attributes['menopause'] = ('lt40', 'ge40', 'premeno')\n",
    "    attributes['tumor-size'] = ('0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44','45-49', '50-54', '55-59')\n",
    "    attributes['inv-nodes'] = ('0-2', '3-5', '6-8', '9-11', '12-14', '15-17', '18-20', '21-23', '24-26', '27-29', '30-32', '33-35', '36-39')\n",
    "    attributes['node-caps'] = ('yes', 'no')\n",
    "    attributes['deg-malig'] = (1,2,3)\n",
    "    attributes['breast'] = ('left', 'right')\n",
    "    attributes['breast-quad'] = ('left-up', 'left-low', 'right-up', 'right-low', 'central')\n",
    "    attributes['irradiat'] = ('yes', 'no')\n",
    "\n",
    "    classes = ['no-recurrence-events', 'recurrence-events']\n",
    "\n",
    "    s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "    s.run_simulation()\n",
    "    accuracies.append(s.evaluate_discovered_rules(test))\n",
    "    num_rules.append(len(s.discovered_rules))\n",
    "    \n",
    "\n",
    "print('Average Accuracy is: ', np.mean(accuracies))\n",
    "print('Accuracy std. is: ', np.std(accuracies))\n",
    "print('Average number of rules per ruleset is: ', np.mean(num_rules))\n",
    "print('Number of rules per ruleset std. is', np.std(num_rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweeping number of Ants\n",
    "#### Warning! These cells take a really long time to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTjBmZlYKJxgzMyvF/wcjzSfDXlwp6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of times to run the miner\n",
    "num_runs = 30\n",
    "# Number of ants to use\n",
    "num_ants_vec = [5, 10, 15, 20, 25]\n",
    "\n",
    "all_accuracies = []\n",
    "all_num_rules = []\n",
    "all_num_terms = []\n",
    "for num_ants in num_ants_vec:\n",
    "    all_accuracies.append([])\n",
    "    all_num_rules.append([])\n",
    "    all_num_terms.append([])\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        train, test = get_train_and_test_from_file('../data/breast-cancer-wisconsin.data', 'wisconsin')\n",
    "        attribute_list = ['Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses']\n",
    "        attributes = {}\n",
    "        for attribute in attribute_list:\n",
    "            attributes[attribute] = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "        classes = ['2', '4']\n",
    "\n",
    "        s = Catagorization(num_ants, 10, train, attributes, classes)\n",
    "        s.run_simulation(supress_output = True)\n",
    "        all_accuracies[-1].append(s.evaluate_discovered_rules(test))\n",
    "        all_num_rules[-1].append(len(s.discovered_rules))\n",
    "        all_num_terms[-1].append(np.mean([len(rule[1]) for rule in s.discovered_rules]))\n",
    "        \n",
    "plt.boxplot(all_accuracies, positions=[n/5 for n in num_ants_vec])\n",
    "plt.title('Accuracy vs Number of Ants Used (Wisconsin Breast Cancer)')\n",
    "plt.xlabel('Number of Ants Used (x5)')\n",
    "plt.ylabel('Accuracy of Ruleset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
